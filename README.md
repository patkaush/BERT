# Intro to AI Course Project – BERT-based Text Processing

This project implements a BERT-based model using the HuggingFace Transformers library. It was developed as part of an Advanced AI course to demonstrate the application of pretrained language models for natural language processing.

## Project Overview

This notebook utilizes a BERT model for fine-tuning on a text dataset inspired from Tensorflow examples. The workflow includes:
- Loading and preprocessing text data
- Tokenization using BERT tokenizer
- Building a classification model using a pretrained BERT base
- Training and evaluating the model

## Files

- `bert_model.ipynb` – Jupyter Notebook containing the complete code for data processing, model setup, training, and evaluation.
- `README.md` – Project documentation and instructions.


## Running the Project

1. Install the required libraries:
   ```bash
   pip install transformers torch pandas numpy scikit-learn matplotlib seaborn
